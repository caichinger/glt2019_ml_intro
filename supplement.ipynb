{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Material\n",
    "\n",
    "Additional material helpful during the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Impact of Model Parameter Settings / Over- and Underfitting\n",
    "\n",
    "What happens when we adjust the model parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "from util import DATA_PATH_PREPROCESSED, TARGET, FEATURES\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSORS = {\n",
    "    'DecisionTree': DecisionTreeRegressor, \n",
    "    'RandomForest': RandomForestRegressor,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_sine(n=100):\n",
    "    prng = np.random.RandomState(123)\n",
    "    X = np.sort(prng.rand(n))\n",
    "    y = np.sin(2 * np.pi * X)\n",
    "    y += prng.normal(0, 0.1, len(y))\n",
    "    y[5::10] += 2*(0.5 - prng.rand(len(y[5::10])))\n",
    "    X_true = np.linspace(0, 1, n)\n",
    "    y_true = np.sin(2 * np.pi * X_true)\n",
    "    return X_true, y_true, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5432000d2842437d9fdb029de4fc64a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='clf', options=('DecisionTree', 'RandomForest'), value='DecisionTre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def regression(clf='DecisionTree', n_estimators=1, min_samples_leaf=1, max_depth=None):\n",
    "    \n",
    "    kws = {\n",
    "        'max_depth': max_depth, \n",
    "        'min_samples_leaf': min_samples_leaf, \n",
    "        'n_estimators': n_estimators,\n",
    "    }\n",
    "    \n",
    "    regr_cls = REGRESSORS[clf]\n",
    "    supported_kws = {k: v for k, v in kws.items() if k in inspect.getfullargspec(regr_cls).args}    \n",
    "    regr = regr_cls(**supported_kws, random_state=42)\n",
    "\n",
    "    X_true, y_true, X, y = create_noisy_sine(n=80)\n",
    "    regr.fit(X.reshape((-1, 1)), y)\n",
    "    yp = regr.predict(X.reshape((-1, 1)))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter(X, y, s=20, color='green', edgecolor='black', label='noisy data')\n",
    "    ax.plot(X_true, y_true, label='true')\n",
    "    ax.plot(X, yp, color='red', label='pred')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y = sin(2pi x)')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "interactive_plot = interactive(\n",
    "    regression, \n",
    "    clf=['DecisionTree', 'RandomForest'],\n",
    "    max_depth=[1, 3, 5, 10, None],\n",
    "    n_estimators=[1, 2, 5, 10, 50, 100, 200, 500, 1000], \n",
    "    min_samples_leaf=[1, 3, 5, 10],\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    'moons': make_moons(noise=0.3, random_state=42), \n",
    "    'circles': make_circles(noise=0.2, factor=0.5, random_state=42),\n",
    "    'linear': make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                                  random_state=42, n_clusters_per_class=1, flip_y=0.1),\n",
    "}\n",
    "\n",
    "CLASSIFIERS = {\n",
    "    'DecisionTree': DecisionTreeClassifier, \n",
    "    'RandomForest': RandomForestClassifier,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845d5213f1bf4a37a00810b905212df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='clf', options=('DecisionTree', 'RandomForest'), value='DecisionTre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def classification(clf='DecisionTree', data='linear', max_depth=None, n_estimators=1, min_samples_leaf=1, max_features=1):\n",
    "\n",
    "    kws = {\n",
    "        'max_depth': max_depth, \n",
    "        'min_samples_leaf': min_samples_leaf, \n",
    "        'max_features': max_features, \n",
    "        'n_estimators': n_estimators, \n",
    "    }\n",
    "    \n",
    "    # prepare model\n",
    "    clf_cls = CLASSIFIERS[clf]\n",
    "    supported_kws = {k: v for k, v in kws.items() if k in inspect.getfullargspec(clf_cls).args}\n",
    "    clf = clf_cls(**supported_kws, random_state=42)\n",
    "    \n",
    "    # prepare data\n",
    "    X, y = DATASETS[data]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = .02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))    \n",
    "    \n",
    "    # define color scheme\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    cm_bright_other = ListedColormap(['#FF8000', '#0080FF'])\n",
    "\n",
    "    # fit predict\n",
    "    clf.fit(X_train, y_train)\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=0.6)\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k', label='train')\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright_other,\n",
    "               edgecolors='k', label='test')\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "interactive_plot = interactive(\n",
    "    classification,\n",
    "    data=['moons', 'circles', 'linear'],\n",
    "    clf=['DecisionTree', 'RandomForest'], \n",
    "    max_depth=[1, 3, 5, None],\n",
    "    n_estimators=[1, 10, 100, 500],\n",
    "    min_samples_leaf=[1, 2, 5],\n",
    "    max_features=[1, 2],\n",
    ")\n",
    "interactive_plot"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
